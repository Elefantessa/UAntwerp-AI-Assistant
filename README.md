# ğŸ“ UAntwerp Academic RAG System

> **Enterprise-Grade Retrieval-Augmented Generation Pipeline for University Programme Information**

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![LangChain](https://img.shields.io/badge/LangChain-1.x-green.svg)](https://langchain.com)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-Vector%20Store-orange.svg)](https://trychroma.com)

A production-ready RAG (Retrieval-Augmented Generation) system designed to provide accurate, context-aware answers about the University of Antwerp's Master in Computer Science programmes. Built with a focus on **modularity**, **scalability**, and **maintainability**.

---

## ğŸŒŸ Key Highlights

| Feature | Description |
|---------|-------------|
| ğŸ—ï¸ **Modular Architecture** | Clean separation of concerns across 8 distinct modules |
| âš¡ **High Performance** | Async web scraping, GPU-accelerated embeddings, batch processing |
| ğŸ¯ **Advanced Retrieval** | MMR diversity search + Cross-Encoder reranking for precision |
| ğŸ§  **Intelligent Processing** | Entity extraction, intent classification, confidence scoring |
| ğŸ”„ **LangGraph Pipeline** | State-machine orchestration for complex workflows |
| ğŸ“Š **Multi-Factor Confidence** | 5-factor scoring with semantic coherence validation |

---

## ğŸ§  How It Works: Question-Answering Pipeline

The system processes queries through a sophisticated multi-stage pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER QUERY                                           â”‚
â”‚                 "What are the admission requirements?"                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: QUERY ANALYSIS                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â€¢ Intent Classification (FACTUAL, PROCEDURAL, COMPARISON, etc.)     â”‚   â”‚
â”‚  â”‚ â€¢ Entity Extraction (programmes, courses, lecturers, dates)         â”‚   â”‚
â”‚  â”‚ â€¢ Keyword Expansion & Query Refinement                              â”‚   â”‚
â”‚  â”‚ â€¢ Metadata Filter Generation                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: INTELLIGENT RETRIEVAL                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â€¢ MMR Search (Maximal Marginal Relevance) for diversity             â”‚   â”‚
â”‚  â”‚ â€¢ Semantic similarity via SFR-Embedding-Mistral (4096-dim)          â”‚   â”‚
â”‚  â”‚ â€¢ Metadata filtering by programme/page_type                         â”‚   â”‚
â”‚  â”‚ â€¢ Fetch k=100 candidates â†’ Return top k=50                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: CROSS-ENCODER RERANKING                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â€¢ ms-marco-MiniLM cross-encoder for query-document scoring          â”‚   â”‚
â”‚  â”‚ â€¢ Re-scores all candidates with full attention                      â”‚   â”‚
â”‚  â”‚ â€¢ Selects top-12 most relevant documents                            â”‚   â”‚
â”‚  â”‚ â€¢ Provides reranking confidence scores                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: CONTEXT MANAGEMENT                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â€¢ Token budget management (2000 tokens max)                         â”‚   â”‚
â”‚  â”‚ â€¢ Source de-duplication                                             â”‚   â”‚
â”‚  â”‚ â€¢ Context expansion for completeness                                â”‚   â”‚
â”‚  â”‚ â€¢ Priority ranking by relevance score                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: ANSWER GENERATION                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STRICT MODE (Primary):                                              â”‚   â”‚
â”‚  â”‚ â€¢ JSON-structured output                                            â”‚   â”‚
â”‚  â”‚ â€¢ Answers ONLY from retrieved context                               â”‚   â”‚
â”‚  â”‚ â€¢ Explicit "I don't know" for missing information                   â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚ FLEXIBLE MODE (Fallback):                                           â”‚   â”‚
â”‚  â”‚ â€¢ Can use general knowledge                                         â”‚   â”‚
â”‚  â”‚ â€¢ Clear distinction of sourced vs. general info                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: CONFIDENCE SCORING                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Multi-Factor Confidence Calculation:                                â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   Reranking Score â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 30%                        â”‚   â”‚
â”‚  â”‚   Entity Match â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 20%                        â”‚   â”‚
â”‚  â”‚   Semantic Coherence (LLM-based) â”€â”€â”€â”€â”€â”€â”€ 20%                        â”‚   â”‚
â”‚  â”‚   Source Diversity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 15%                        â”‚   â”‚
â”‚  â”‚   Context Completeness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 15%                        â”‚   â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚   â”‚
â”‚  â”‚   Final Confidence Score â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 100%                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RESPONSE                                             â”‚
â”‚  {                                                                          â”‚
â”‚    "answer": "Detailed answer with source citations...",                    â”‚
â”‚    "confidence": 0.85,                                                      â”‚
â”‚    "sources": ["url1", "url2"],                                            â”‚
â”‚    "contexts": [...]                                                        â”‚
â”‚  }                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER INTERFACE                                â”‚
â”‚                    (Flask API + Web Chat Interface)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           API LAYER                                     â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚         â”‚ /api/query  â”‚    â”‚ /api/health  â”‚    â”‚ /api/chat      â”‚      â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SERVICE LAYER                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      RAG SERVICE                                 â”‚   â”‚
â”‚  â”‚    (LangGraph State Machine Orchestration)                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    Ollama Service    â”‚          â”‚      Query Processor          â”‚   â”‚
â”‚  â”‚   (LLM Interface)    â”‚          â”‚  (Intent + Entity Extraction) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CORE LAYER                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Retrieval    â”‚  â”‚   Generation   â”‚  â”‚      Processors         â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚ â”‚VectorStore â”‚ â”‚  â”‚ â”‚StrictGen   â”‚ â”‚  â”‚ â”‚QueryProcessor       â”‚ â”‚   â”‚
â”‚  â”‚ â”‚Reranker    â”‚ â”‚  â”‚ â”‚FlexibleGen â”‚ â”‚  â”‚ â”‚ConfidenceCalculator â”‚ â”‚   â”‚
â”‚  â”‚ â”‚Expander    â”‚ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DATA LAYER                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚       ChromaDB               â”‚   â”‚      Ollama (LLM)             â”‚  â”‚
â”‚  â”‚  (Vector Embeddings Store)   â”‚   â”‚   llama3.1:latest             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Structure

```
pipline/
â”œâ”€â”€ main.py                      # Application entry point
â”œâ”€â”€ run_indexing.py              # Indexing pipeline CLI
â”œâ”€â”€ run_evaluation.py            # ğŸ“ˆ RAGAS evaluation CLI
â”œâ”€â”€ requirements.txt             # Dependencies
â”‚
â”œâ”€â”€ config/                      # âš™ï¸ Configuration
â”‚   â”œâ”€â”€ settings.py              # Dataclass-based settings
â”‚   â””â”€â”€ logging_config.py        # Logging setup
â”‚
â”œâ”€â”€ core/                        # ğŸ§  Core Business Logic
â”‚   â”œâ”€â”€ models/                  # Data models
â”‚   â”‚   â”œâ”€â”€ state.py             # LangGraph state schema
â”‚   â”‚   â”œâ”€â”€ response.py          # Response dataclasses
â”‚   â”‚   â””â”€â”€ entities.py          # Query entities
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/              # Processing logic
â”‚   â”‚   â”œâ”€â”€ query_processor.py   # Intent & entity extraction
â”‚   â”‚   â””â”€â”€ confidence_calculator.py  # Multi-factor scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/               # Retrieval components
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB manager
â”‚   â”‚   â”œâ”€â”€ reranker.py          # Cross-encoder reranking
â”‚   â”‚   â””â”€â”€ context_expander.py  # Token budget management
â”‚   â”‚
â”‚   â””â”€â”€ generation/              # Answer generation
â”‚       â”œâ”€â”€ base_generator.py    # Abstract base class
â”‚       â”œâ”€â”€ strict_generator.py  # Context-only answers
â”‚       â””â”€â”€ flexible_generator.py # General knowledge fallback
â”‚
â”œâ”€â”€ evaluation/                  # ğŸ“ˆ RAGAS Evaluation
â”‚   â”œâ”€â”€ __init__.py              # Module exports
â”‚   â”œâ”€â”€ config.py                # Evaluation configuration
â”‚   â”œâ”€â”€ ragas_evaluator.py       # RAGAS metrics wrapper
â”‚   â””â”€â”€ tester.py                # RAG testing framework
â”‚
â”œâ”€â”€ services/                    # ğŸ”§ Service Layer
â”‚   â”œâ”€â”€ rag_service.py           # LangGraph orchestrator
â”‚   â””â”€â”€ ollama_service.py        # LLM client wrapper
â”‚
â”œâ”€â”€ api/                         # ğŸŒ Web API
â”‚   â”œâ”€â”€ app.py                   # Flask factory
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.py              # Query endpoints
â”‚   â”‚   â””â”€â”€ health.py            # Health checks
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ chat.html            # Web interface
â”‚
â”œâ”€â”€ utils/                       # ğŸ› ï¸ Utilities
â”‚   â”œâ”€â”€ json_utils.py            # JSON parsing
â”‚   â””â”€â”€ text_utils.py            # Text processing
â”‚
â””â”€â”€ indexing/                    # ğŸ“¥ Data Ingestion
    â”œâ”€â”€ scraper/                 # Web scraping
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ url_utils.py
    â”‚   â”œâ”€â”€ html_cleaner.py
    â”‚   â”œâ”€â”€ markdown_converter.py
    â”‚   â””â”€â”€ scraper.py
    â”‚
    â”œâ”€â”€ chunker/                 # Text chunking
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ token_estimator.py
    â”‚   â”œâ”€â”€ text_utils.py
    â”‚   â””â”€â”€ chunker.py
    â”‚
    â””â”€â”€ ingestor/                # ChromaDB ingestion
        â”œâ”€â”€ config.py
        â”œâ”€â”€ metadata_utils.py
        â”œâ”€â”€ device_planner.py
        â”œâ”€â”€ embeddings.py
        â””â”€â”€ ingestor.py
```

---

## ğŸ¯ Technical Strengths

### 1. **Production-Ready Architecture**
- Clean separation of concerns following SOLID principles
- Dependency injection for testability
- Dataclass-based configuration for type safety
- Comprehensive error handling with graceful fallbacks

### 2. **Advanced NLP Pipeline**
- **State-of-the-Art Embeddings**: Salesforce SFR-Embedding-Mistral (4096 dimensions)
- **Two-Stage Retrieval**: MMR search + Cross-encoder reranking
- **Entity-Aware Processing**: Automatic extraction of programmes, courses, lecturers
- **Intent Classification**: FACTUAL, PROCEDURAL, COMPARISON, EXPLORATORY, SPECIFIC

### 3. **Robust Confidence Scoring**
```python
confidence = (
    rerank_score * 0.30 +      # Cross-encoder relevance
    entity_match * 0.20 +       # Query-answer entity overlap
    semantic_coherence * 0.20 + # LLM-based validation
    source_diversity * 0.15 +   # Multiple source agreement
    context_completeness * 0.15 # Coverage of query aspects
)
```

### 4. **Scalable Indexing Pipeline**
- Async web scraping with concurrency control
- Robots.txt compliance
- Content deduplication (per-programme)
- GPU-accelerated batch embedding
- Token-aware hybrid chunking

### 5. **Developer Experience**
- Unified CLI for all operations
- Comprehensive logging
- Modular design for easy extension
- Well-documented codebase

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Ollama with llama3.1 model
- CUDA-capable GPU (recommended)

### Installation

```bash
# Clone and setup
pip install -r web_pipline/pipline/requirements.txt

# Start Ollama (if not running)
ollama serve &
ollama pull llama3.1
```

### Run Indexing Pipeline

```bash
cd web_pipline/pipline

# Full pipeline (recommended for first run)
python run_indexing.py --full

# With custom settings
python run_indexing.py --full --max-pages 50 --recreate
```

### Start API Server

```bash
python main.py \
  --persist-dir /path/to/chroma_db \
  --collection uantwerp_cs_web \
  --port 5006
```

### Test the System

```bash
# Health check
curl http://localhost:5006/api/health

# Query example
curl -X POST http://localhost:5006/api/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What are the admission requirements for Data Science?"}'
```

---

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| **Indexing Speed** | 34 pages â†’ 92 chunks in 126s |
| **Query Latency** | < 5 seconds (with GPU) |
| **Embedding Model** | SFR-Embedding-Mistral (4096-dim) |
| **Context Window** | 2000 tokens |
| **Confidence Range** | 0.0 - 1.0 |

---

## ğŸ› ï¸ Configuration Reference

### Environment Settings (`config/settings.py`)

| Config | Parameter | Default |
|--------|-----------|---------|
| **Model** | `ollama_model` | llama3.1:latest |
| **Model** | `embed_model` | SFR-Embedding-Mistral |
| **RAG** | `k` | 50 documents |
| **RAG** | `token_budget` | 2000 tokens |
| **Indexing** | `max_pages_per_seed` | 100 |
| **Indexing** | `target_tokens` | 350 per chunk |

---

## ğŸ“ˆ RAGAS Evaluation

The system includes comprehensive evaluation capabilities using **RAGAS** (Retrieval Augmented Generation Assessment) framework with local Ollama models.

### Evaluation Metrics

| Metric | Description |
|--------|-------------|
| **Answer Relevancy** | How relevant the answer is to the question |
| **Context Precision** | Proportion of relevant context chunks |
| **Context Recall** | How well the retrieved context covers the ground truth |
| **Faithfulness** | How grounded the answer is in the retrieved context |
| **Answer Correctness** | Semantic similarity to ground truth answers |

### Recommended Models for Evaluation

| Model | Size | JSON Quality | Speed | Notes |
|-------|------|--------------|-------|-------|
| **qwen2.5:14b** â­ | 9GB | â­â­â­â­â­ | Medium | Best balance - all metrics work |
| **qwen2.5:7b** | 4.7GB | â­â­â­â­ | Fast | Good for quick evaluations |
| **mistral:7b** | 4.1GB | â­â­â­â­ | Fast | Reliable JSON output |
| **gemma2:9b** | 5.4GB | â­â­â­â­â­ | Medium | From Google |
| **llama3.1:8b** | 4.9GB | â­â­â­ | Fast | Some metrics may fail |
| **gpt-oss:latest** | 13GB | â­â­â­â­ | Slow | May timeout on some metrics |

### Running Evaluation

```bash
cd web_pipline/pipline

# Make sure the RAG API is running first
python main.py --persist-dir ../data/db/unified_chroma_db --port 5007

# Run evaluation with recommended model (in another terminal)
python run_evaluation.py \
  --questions /web_pipline/data/evaluation/sample_questions.json \
  --provider ollama \
  --llm-model qwen2.5:14b \
  --api-url http://127.0.0.1:5007

# Generate sample questions file
python run_evaluation.py --generate-sample
```

### Evaluation Results Example

```
ğŸ“ˆ RAGAS Scores:
  answer_relevancy: 0.5275
  context_precision: 0.3000
  context_recall: 0.4000
  faithfulness: 0.6867
  answer_correctness: 0.3982

  ğŸ“Š Average: 0.4625
```

### Installing Evaluation Models

```bash
# Recommended model (best balance)
ollama pull qwen2.5:14b

# Alternative models
ollama pull qwen2.5:7b
ollama pull mistral:7b-instruct
ollama pull gemma2:9b

# Required for embeddings
ollama pull nomic-embed-text
```

### Evaluation Configuration

The evaluation uses:
- **LLM**: Configurable via `--llm-model` (default: `gpt-oss:latest`)
- **Embeddings**: `nomic-embed-text` via Ollama
- **Provider**: `ollama` (local) or `openai` (API)

### Output Files

Results are saved to `/web_pipline/data/evaluation/`:
- `rag_results_TIMESTAMP.jsonl` - Detailed RAG responses
- `ragas_scores_TIMESTAMP.json` - RAGAS metric scores
- `evaluation_report_TIMESTAMP.md` - Human-readable report

---

## ğŸ“„ License

University of Antwerp - Master in Computer Science Project

---

## ğŸ‘¤ Author

**Hala Alramli**
